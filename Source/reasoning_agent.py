import re
import logging
from typing import List, Dict, Any
from sentence_transformers import CrossEncoder
import numpy as np

from base_agent import BaseAgent, AgentType, ProcessingState
from llm import generate_advanced
from config import *

logger = logging.getLogger(__name__)

class ReasoningAgent(BaseAgent):
    """TÃ­ch há»£p reranking vÃ  response generation"""
    
    def __init__(self):
        super().__init__("ReasoningAgent", AgentType.REASONING)
        
        # Initialize models
        try:
            self.cross_encoder = CrossEncoder(CE_MODEL, cache_folder=CACHE_DIR)
        except:
            self.cross_encoder = None
            logger.warning("Cross-encoder not available, skipping reranking")
    
    async def process(self, state: ProcessingState) -> ProcessingState:
        """Execute reranking + response generation"""
        
        if not state.retrieved_docs:
            state.final_response = "Xin lá»—i, tÃ´i khÃ´ng tÃ¬m tháº¥y thÃ´ng tin phÃ¹ há»£p."
            state.confidence = 0.1
            return state
        
        # Step 1: Reranking
        reranked_docs = await self._rerank_documents(state.query, state.retrieved_docs)
        state.reranked_docs = reranked_docs
        
        # Step 2: Build response vá»›i citations
        response_data = await self._generate_response(state)
        state.final_response = response_data["answer"]
        state.confidence = response_data["confidence"]
        
        state.reasoning_chain.extend([
            f"Reranked {len(state.retrieved_docs)} -> {len(reranked_docs)} documents",
            f"Generated response with confidence: {state.confidence:.2%}"
        ])
        
        return state
    
    async def _rerank_documents(self, query: str, docs: List[Dict]) -> List[Dict]:
        """Rerank documents using cross-encoder"""
        
        if not self.cross_encoder or len(docs) <= 1:
            return docs[:TOP_K_RERANK]
        
        try:
            # Prepare query-document pairs
            pairs = []
            for doc in docs:
                doc_text = doc.get("text", "")[:512]  # Truncate for efficiency
                pairs.append([query, doc_text])
            
            # Get cross-encoder scores
            cross_scores = self.cross_encoder.predict(pairs)
            
            # Combine vá»›i vector similarity scores
            final_scores = []
            for i, doc in enumerate(docs):
                vector_score = doc.get("similarity_score", 0.0)
                cross_score = cross_scores[i]
                
                # Weighted combination
                combined_score = 0.7 * cross_score + 0.3 * vector_score
                final_scores.append(combined_score)
                
                # Add score to document
                doc["rerank_score"] = combined_score
            
            # Sort by combined score
            sorted_indices = np.argsort(final_scores)[::-1]
            reranked_docs = [docs[i] for i in sorted_indices[:TOP_K_RERANK]]
            
            return reranked_docs
            
        except Exception as e:
            logger.error(f"Reranking failed: {e}")
            return docs[:TOP_K_RERANK]
    
    async def _generate_response(self, state: ProcessingState) -> Dict[str, Any]:
        """Generate response with citations vÃ  XAI"""
        
        # Build enhanced prompt
        prompt = self._build_enhanced_prompt(state)
        
        # Generate using LLM
        try:
            llm_result = generate_advanced(prompt, state.reranked_docs)
            
            # Process citations
            processed_answer = self._process_citations(
                llm_result["answer"], 
                state.reranked_docs
            )
            
            # Calculate confidence
            confidence = self._calculate_confidence(state.reranked_docs, llm_result)
            
            return {
                "answer": processed_answer,
                "confidence": confidence,
                "success": True
            }
            
        except Exception as e:
            logger.error(f"Response generation failed: {e}")
            return {
                "answer": "Xin lá»—i, Ä‘Ã£ cÃ³ lá»—i xáº£y ra trong quÃ¡ trÃ¬nh táº¡o pháº£n há»“i.",
                "confidence": 0.1,
                "success": False
            }
    
    def _build_enhanced_prompt(self, state: ProcessingState) -> str:
        """Build prompt vá»›i hexagram context + specialized templates"""
        
        # Build context tá»« documents (giá»¯ tá»« phiÃªn báº£n má»›i)
        context_parts = []
        for i, doc in enumerate(state.reranked_docs[:8], 1):
            text = doc.get("text", "")
            if len(text) > 400:
                text = text[:400] + "..."
            
            hexagram = doc.get("hexagram", "")
            content_type = doc.get("content_type", "")
            
            context_entry = f"[{i}] "
            if hexagram:
                context_entry += f"Quáº» {hexagram} - "
            if content_type:
                context_entry += f"({content_type}) "
            context_entry += text
            
            context_parts.append(context_entry)
        
        context = "\n\n".join(context_parts)
        
        # Build hexagram context (giá»¯ tá»« phiÃªn báº£n má»›i)
        hexagram_context = ""
        if state.hexagram_info and state.hexagram_info.get("name"):
            info = state.hexagram_info
            hexagram_context = f"""THÃ”NG TIN QUáºº ÄÃƒ GIEO:
- TÃªn quáº»: {info.get('name', 'N/A')}
- Ã nghÄ©a chung: {info.get('general_meaning', 'N/A')}
- HÃ o Ä‘á»™ng (náº¿u cÃ³): {info.get('changing_lines', 'KhÃ´ng cÃ³')}
"""

        # HYBRID: Specialized templates theo query type (tá»« phiÃªn báº£n cÅ©) + hexagram context (tá»« phiÃªn báº£n má»›i)
        return self._get_specialized_prompt(state.query_type, hexagram_context, state.query, context)
    
    def _get_specialized_prompt(self, query_type: str, hexagram_context: str, query: str, context: str) -> str:
        """Get specialized prompt template based on query type"""
        
        if query_type == "divination":
            return f"""Báº¡n lÃ  chuyÃªn gia Kinh Dá»‹ch cÃ³ kinh nghiá»‡m sÃ¢u rá»™ng, chuyÃªn vá» giáº£i quáº» vÃ  tÆ° váº¥n Ä‘á»‹nh hÆ°á»›ng.

{hexagram_context}

âš ï¸  QUAN TRá»ŒNG: Báº¡n PHáº¢I phÃ¢n tÃ­ch quáº» Ä‘Ã£ gieo á»Ÿ trÃªn, KHÃ”NG Ä‘Æ°á»£c nháº§m láº«n vá»›i cÃ¡c quáº» khÃ¡c trong tÃ i liá»‡u tham kháº£o.

CÃ‚U Há»ŽI GIEO QUáºº: "{query}"

TÃ€I LIá»†U THAM KHáº¢O (chá»‰ Ä‘á»ƒ há»— trá»£):
{context}

YÃŠU Cáº¦U NGHIÃŠM NGáº¶T:
1. **FOCUS CHÃNH vÃ o quáº» Ä‘Ã£ gieo**: PhÃ¢n tÃ­ch chÃ­nh xÃ¡c quáº» Ä‘Ã£ Ä‘Æ°á»£c gieo (xem pháº§n "THÃ”NG TIN QUáºº ÄÃƒ GIEO")
2. **KHÃ”NG nháº§m láº«n quáº»**: Náº¿u tÃ i liá»‡u tham kháº£o Ä‘á» cáº­p Ä‘áº¿n quáº» khÃ¡c, chá»‰ dÃ¹ng Ä‘á»ƒ há»— trá»£ thÃ´ng tin, KHÃ”NG phÃ¢n tÃ­ch thay tháº¿
3. **PhÃ¢n tÃ­ch quáº» vÃ  tÃ¬nh huá»‘ng**: Káº¿t há»£p Ã½ nghÄ©a quáº» Ä‘Ã£ gieo vá»›i bá»‘i cáº£nh cÃ¢u há»i cá»¥ thá»ƒ
4. **Lá»i khuyÃªn thá»±c táº¿**: ÄÆ°a ra Ä‘á»‹nh hÆ°á»›ng rÃµ rÃ ng, hÃ nh Ä‘á»™ng cá»¥ thá»ƒ dá»±a trÃªn quáº» Ä‘Ã£ gieo
5. **Giáº£i thÃ­ch Ã½ nghÄ©a sÃ¢u sáº¯c**: PhÃ¢n tÃ­ch táº§ng lá»›p áº©n Ã½ cá»§a quáº» Ä‘Ã£ gieo
6. **TrÃ­ch dáº«n nguá»“n**: Sá»­ dá»¥ng [sá»‘] Ä‘á»ƒ tham chiáº¿u tÃ i liá»‡u (náº¿u phÃ¹ há»£p)
7. **Giá»ng vÄƒn**: Trang trá»ng, tháº¥u hiá»ƒu vÃ  Ä‘á»“ng cáº£m

ðŸŽ¯ LÆ¯U Ã: Náº¿u tÃ i liá»‡u tham kháº£o nÃ³i vá» quáº» khÃ¡c, hÃ£y nÃ³i rÃµ "TÃ i liá»‡u Ä‘á» cáº­p Ä‘áº¿n quáº» [tÃªn], nhÆ°ng quáº» báº¡n Ä‘Ã£ gieo lÃ  [tÃªn quáº» Ä‘Ã£ gieo]"

TRáº¢ Lá»œI:"""
        
        elif query_type == "philosophy":
            context_section = f"\n\nTÃ€I LIá»†U THAM KHáº¢O:\n{context}" if context.strip() else ""
            hexagram_section = f"\n{hexagram_context}" if hexagram_context.strip() else ""
            
            return f"""Báº¡n lÃ  há»c giáº£ Kinh Dá»‹ch uyÃªn thÃ¢m, am hiá»ƒu sÃ¢u sáº¯c vá» triáº¿t lÃ½ ÄÃ´ng phÆ°Æ¡ng.{hexagram_section}

CÃ‚U Há»ŽI TRIáº¾T Há»ŒC: "{query}"{context_section}

YÃŠU Cáº¦U:
1. **Giáº£i thÃ­ch triáº¿t lÃ½ sÃ¢u sáº¯c**: PhÃ¢n tÃ­ch báº£n cháº¥t vÃ  nguá»“n gá»‘c tÆ° tÆ°á»Ÿng
2. **Káº¿t ná»‘i tÆ° tÆ°á»Ÿng ÄÃ´ng phÆ°Æ¡ng**: LiÃªn há»‡ vá»›i cÃ¡c trÆ°á»ng phÃ¡i khÃ¡c
3. **VÃ­ dá»¥ minh há»a**: ÄÆ°a ra cÃ¡c vÃ­ dá»¥ cá»¥ thá»ƒ, dá»… hiá»ƒu
4. **TrÃ­ch dáº«n nguá»“n**: Sá»­ dá»¥ng [sá»‘] Ä‘á»ƒ tham chiáº¿u tÃ i liá»‡u
5. **Giá»ng vÄƒn**: Há»c thuáº­t, khÃ¡ch quan vÃ  sÃ¢u sáº¯c

TRáº¢ Lá»œI:"""
        
        else:  # General or hexagram-specific
            context_section = f"\n\nTÃ€I LIá»†U THAM KHáº¢O:\n{context}" if context.strip() else ""
            hexagram_section = f"\n{hexagram_context}" if hexagram_context.strip() else ""
            
            return f"""Báº¡n lÃ  chuyÃªn gia Kinh Dá»‹ch vá»›i kiáº¿n thá»©c toÃ n diá»‡n vá» há»‡ thá»‘ng 64 quáº».{hexagram_section}

CÃ‚U Há»ŽI: "{query}"{context_section}

YÃŠU Cáº¦U:
1. **Tráº£ lá»i chÃ­nh xÃ¡c**: Dá»±a trÃªn tÃ i liá»‡u vÃ  kiáº¿n thá»©c Kinh Dá»‹ch
2. **Giáº£i thÃ­ch rÃµ rÃ ng**: Dá»… hiá»ƒu, cÃ³ cáº¥u trÃºc logic
3. **ThÃ´ng tin há»¯u Ã­ch**: Cung cáº¥p insight cÃ³ giÃ¡ trá»‹ thá»±c táº¿
4. **TrÃ­ch dáº«n nguá»“n**: Sá»­ dá»¥ng [sá»‘] Ä‘á»ƒ tham chiáº¿u tÃ i liá»‡u
5. **Giá»ng vÄƒn**: ThÃ¢n thiá»‡n, chuyÃªn nghiá»‡p vÃ  dá»… tiáº¿p cáº­n

TRáº¢ Lá»œI:"""
    
    def _process_citations(self, answer: str, docs: List[Dict]) -> str:
        """Process citations - thay tháº¿ [n] báº±ng ná»™i dung notes"""
        
        def replace_citation(match):
            try:
                cite_num = int(match.group(1))
                if 1 <= cite_num <= len(docs):
                    doc = docs[cite_num - 1]
                    notes = doc.get("original_chunk", {}).get("notes", {})
                    
                    # If cÃ³ notes cho citation number nÃ y
                    if str(cite_num) in notes:
                        return f" ({notes[str(cite_num)]}) "
                    
                    # Fallback: return original citation
                    return match.group(0)
                else:
                    return match.group(0)
            except:
                return match.group(0)
        
        # Replace [n] vá»›i ná»™i dung notes
        processed_answer = re.sub(r'\[(\d+)\]', replace_citation, answer)
        
        return processed_answer
    
    def _calculate_confidence(self, docs: List[Dict], llm_result: Dict) -> float:
        """Calculate overall confidence score"""
        
        if not docs:
            return 0.1
        
        # Document relevance confidence
        doc_scores = [doc.get("rerank_score", doc.get("similarity_score", 0)) for doc in docs]
        doc_confidence = sum(doc_scores) / len(doc_scores) if doc_scores else 0
        
        # LLM confidence
        llm_confidence = llm_result.get("confidence", 0.5)
        
        # Combined confidence
        overall_confidence = (doc_confidence + llm_confidence) / 2
        
        return min(max(overall_confidence, 0.0), 1.0)