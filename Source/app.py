# app.py - Enhanced Multi-Agent Kinh Dich Application
import gradio as gr
import asyncio
from orchestrator import answer_with_agents
from hexagram_caster import HexagramCaster

class MultiAgentKinhDichApp:
    def __init__(self):
        self.hexagram_caster = HexagramCaster()
    
    def create_interface(self):
        with gr.Blocks(title="Multi-Agent Kinh Dá»‹ch Chatbot", theme=gr.themes.Soft()) as interface:
            gr.Markdown("# ğŸ¤– Multi-Agent Kinh Dá»‹ch Chatbot")
            gr.Markdown("ChÃ o má»«ng báº¡n Ä‘áº¿n vá»›i chatbot Kinh Dá»‹ch. HÃ£y lÃ m theo cÃ¡c bÆ°á»›c dÆ°á»›i Ä‘Ã¢y Ä‘á»ƒ nháº­n Ä‘Æ°á»£c luáº­n giáº£i sÃ¢u sáº¯c nháº¥t.")

            with gr.Row():
                # Cá»˜T TRÃI: NHáº¬P LIá»†U VÃ€ ÄIá»€U KHIá»‚N
                with gr.Column(scale=1):
                    gr.Markdown("### BÆ°á»›c 1: Äáº·t cÃ¢u há»i")
                    msg_box = gr.Textbox(
                        placeholder="Nháº­p cÃ¢u há»i hoáº·c mÃ´ táº£ tÃ¬nh huá»‘ng cá»§a báº¡n á»Ÿ Ä‘Ã¢y...",
                        label="CÃ¢u há»i cá»§a báº¡n",
                        lines=3
                    )
                    
                    user_name = gr.Textbox(label="TÃªn (tÃ¹y chá»n)", placeholder="Nháº­p tÃªn cá»§a báº¡n...")

                    gr.Markdown("### BÆ°á»›c 2: Chá»n cÃ¡ch gieo quáº»")
                    casting_type = gr.Radio(
                        choices=[
                            ("ğŸª™ Ba Äá»“ng Xu", "coins"),
                            ("âš¡ Nhanh", "quick"), 
                            ("ğŸ¯ HoÃ n ToÃ n Ngáº«u NhiÃªn", "random"),
                            ("ğŸ§˜ Thiá»n Äá»‹nh", "meditation")
                        ],
                        value="quick",
                        label="Chá»n cÃ¡ch gieo"
                    )

                    gr.Markdown("### BÆ°á»›c 3: Báº¯t Ä‘áº§u luáº­n giáº£i")
                    with gr.Row():
                        main_btn = gr.Button("ğŸ² Gieo Quáº» vÃ  Luáº­n Giáº£i", variant="primary", scale=2)
                        quick_ask_btn = gr.Button("ğŸ’¬ Há»i Nhanh", variant="secondary", scale=1)
                    
                    with gr.Accordion("â„¹ï¸ PhÃ¢n biá»‡t 2 modes", open=False):
                        gr.Markdown("""
**ğŸ² Gieo Quáº» vÃ  Luáº­n Giáº£i:**
- âœ… Gieo quáº» ngáº«u nhiÃªn cho cÃ¢u há»i cá»§a báº¡n
- âœ… PhÃ¢n tÃ­ch tá»•ng há»£p: Quáº» + TÃ¬nh huá»‘ng cÃ¡ nhÃ¢n  
- âœ… Lá»i khuyÃªn Ä‘á»‹nh hÆ°á»›ng cá»¥ thá»ƒ
- ğŸ¯ **DÃ nh cho:** TÆ° váº¥n cÃ¡ nhÃ¢n, Ä‘á»‹nh hÆ°á»›ng cuá»™c sá»‘ng

**ğŸ’¬ Há»i Nhanh:**
- âŒ KhÃ´ng gieo quáº»
- âœ… Tráº£ lá»i thÃ´ng tin tá»« cÆ¡ sá»Ÿ tri thá»©c Kinh Dá»‹ch
- âœ… Giáº£i thÃ­ch khÃ¡i niá»‡m, Ã½ nghÄ©a quáº»
- ğŸ¯ **DÃ nh cho:** Há»c há»i, tÃ¬m hiá»ƒu kiáº¿n thá»©c
                        """)
                    
                    with gr.Accordion("ThÃ´ng tin quáº» Ä‘Ã£ gieo", open=True):
                        cast_result = gr.Textbox(
                            label="Káº¿t quáº£ gieo quáº» sáº½ hiá»ƒn thá»‹ á»Ÿ Ä‘Ã¢y",
                            lines=8,
                            interactive=False
                        )

                    with gr.Accordion("ğŸ¤– Agent Monitoring", open=False):
                        agent_stats = gr.JSON(label="Agent Performance")
                        reasoning_display = gr.JSON(label="Reasoning Chain")
                    
                    clear_chat_btn = gr.Button("ğŸ—‘ï¸ XÃ³a cuá»™c trÃ² chuyá»‡n")

                # Cá»˜T PHáº¢I: HIá»‚N THá»Š Káº¾T QUáº¢
                with gr.Column(scale=2):
                    chatbot_ui = gr.Chatbot(
                        type="messages",
                        height=700,
                        label="Cuá»™c trÃ² chuyá»‡n",
                        render_markdown=True,
                        show_copy_button=True
                    )

            # --- ENHANCED BACKEND LOGIC ---
            async def cast_and_respond(message, history, user_name, cast_type):
                """Integrated workflow: Cast hexagram + AI analysis"""
                if not message.strip():
                    gr.Warning("Vui lÃ²ng nháº­p cÃ¢u há»i cá»§a báº¡n trÆ°á»›c khi gieo quáº».")
                    yield history, "", "", {}, []
                    return

                # 1. Gieo quáº» vá»›i enhanced error handling
                try:
                    cast_obj = self.hexagram_caster.cast_hexagram(f"Gieo quáº» cho cÃ¢u há»i: {message}")
                    
                    hexagram_info_dict = {
                        "name": cast_obj.hexagram_name,
                        "number": cast_obj.hexagram_number,
                        "general_meaning": cast_obj.general_meaning,
                        "structure_str": cast_obj.format_structure(),
                        "changing_lines": cast_obj.changing_lines or "KhÃ´ng cÃ³"
                    }

                    display_info = f"""ğŸ¯ QUáºº: {cast_obj.hexagram_name} ({cast_obj.hexagram_number}/64)
ğŸ“ Ã nghÄ©a: {cast_obj.general_meaning}
---
ğŸ—ï¸ Cáº¥u trÃºc:
{cast_obj.format_structure()}
---
âš¡ HÃ o Ä‘á»™ng: {hexagram_info_dict['changing_lines']}
ğŸ² CÃ¡ch gieo: {cast_type}"""
                    
                except Exception as e:
                    gr.Error(f"Lá»—i khi gieo quáº»: {str(e)}")
                    yield history, message, "", {}, []
                    return

                # 2. ThÃªm cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng vÃ o lá»‹ch sá»­ chat
                history.append(gr.ChatMessage(role="user", content=message))
                
                # ThÃªm thÃ´ng tin quáº» vÃ o lá»‹ch sá»­ chat nhÆ° má»™t bÆ°á»›c riÃªng
                hexagram_chat_message = f"""**ÄÃ£ gieo Ä‘Æ°á»£c quáº»:**

{display_info}"""
                history.append(gr.ChatMessage(
                    role="assistant", 
                    content=hexagram_chat_message,
                    metadata={"title": "Káº¿t quáº£ gieo quáº»"}
                ))

                # 3. Multi-agent analysis vá»›i progress feedback
                progress_message = "ğŸ¤– Äang phÃ¢n tÃ­ch qua Multi-Agent System...\n\n" + \
                                 "ğŸ” Dispatcher â†’ ğŸ—£ï¸ Linguistics â†’ ğŸ“š Retrieval â†’ ğŸ§  Reasoning"
                history.append(gr.ChatMessage(role="assistant", content=progress_message))
                yield history, "", display_info, {}, [] # Cáº­p nháº­t UI ngay láº­p tá»©c

                try:
                    result = await answer_with_agents(message, user_name, hexagram_info=hexagram_info_dict)
                    
                    # XÃ³a tin nháº¯n progress vÃ  thay báº±ng káº¿t quáº£
                    history.pop()
                    
                    # Enhanced response vá»›i metadata
                    response_content = result["answer"]
                    if result.get("confidence", 0) < 0.7:
                        response_content += f"\n\n*Äá»™ tin cáº­y: {result.get('confidence', 0):.1%} - CÃ³ thá»ƒ cáº§n thÃªm thÃ´ng tin Ä‘á»ƒ phÃ¢n tÃ­ch chÃ­nh xÃ¡c hÆ¡n.*"
                    
                    history.append(gr.ChatMessage(
                        role="assistant", 
                        content=response_content,
                        metadata={"title": f"Luáº­n giáº£i hoÃ n táº¥t (Confidence: {result.get('confidence', 0):.1%})"}
                    ))
                    
                except Exception as e:
                    history.pop()  # Remove progress message
                    history.append(gr.ChatMessage(
                        role="assistant", 
                        content=f"âŒ Xin lá»—i, Ä‘Ã£ cÃ³ lá»—i trong quÃ¡ trÃ¬nh phÃ¢n tÃ­ch: {str(e)}"
                    ))
                    result = {"agent_stats": {}, "reasoning_chain": []}
                
                yield (history, "", display_info, 
                        result.get("agent_stats", {}), 
                        result.get("reasoning_chain", []))

            async def quick_respond(message, history, user_name):
                """Pure Q&A mode - No hexagram casting, focus on knowledge base"""
                if not message.strip():
                    gr.Warning("Vui lÃ²ng nháº­p cÃ¢u há»i cá»§a báº¡n.")
                    yield history, "", {}, []
                    return

                # Add user message vá»›i clear mode indicator
                history.append(gr.ChatMessage(role="user", content=message))
                
                # Enhanced progress feedback cho Q&A mode
                progress_message = "ğŸ’¡ Äang tÃ¬m kiáº¿m trong cÆ¡ sá»Ÿ tri thá»©c...\n\n" + \
                                 "ğŸ“š Mode: Há»i Ä‘Ã¡p nhanh (khÃ´ng gieo quáº»)"
                history.append(gr.ChatMessage(role="assistant", content=progress_message))
                yield history, "", {}, []

                try:
                    # Pure Q&A: KhÃ´ng cÃ³ hexagram context
                    result = await answer_with_agents(message, user_name, hexagram_info=None)
                    
                    # Replace progress vá»›i actual response
                    history.pop()
                    
                    # Enhanced response vá»›i mode indicator
                    response_content = result["answer"]
                    
                    # Add confidence indicator náº¿u tháº¥p
                    if result.get("confidence", 0) < 0.6:
                        response_content += f"\n\n*Mode: Há»i Ä‘Ã¡p nhanh | Äá»™ tin cáº­y: {result.get('confidence', 0):.1%}*"
                        response_content += f"\n\nğŸ’¡ *Gá»£i Ã½: Náº¿u cáº§n tÆ° váº¥n cÃ¡ nhÃ¢n, hÃ£y sá»­ dá»¥ng mode 'Gieo Quáº» vÃ  Luáº­n Giáº£i'*"
                    
                    history.append(gr.ChatMessage(
                        role="assistant", 
                        content=response_content,
                        metadata={"title": f"Tráº£ lá»i nhanh (Q&A Mode)"}
                    ))
                    
                    yield (history, "", 
                           result.get("agent_stats", {}), 
                           result.get("reasoning_chain", []))
                           
                except Exception as e:
                    history.pop()
                    history.append(gr.ChatMessage(
                        role="assistant", 
                        content=f"âŒ Xin lá»—i, Ä‘Ã£ cÃ³ lá»—i: {str(e)}"
                    ))
                    yield history, "", {}, []

            # --- EVENT BINDINGS ---
            main_btn.click(
                cast_and_respond,
                inputs=[msg_box, chatbot_ui, user_name, casting_type],
                outputs=[chatbot_ui, msg_box, cast_result, agent_stats, reasoning_display]
            )
            
            quick_ask_btn.click(
                quick_respond,
                inputs=[msg_box, chatbot_ui, user_name],
                outputs=[chatbot_ui, msg_box, agent_stats, reasoning_display]
            )
            
            msg_box.submit(
                cast_and_respond,
                inputs=[msg_box, chatbot_ui, user_name, casting_type],
                outputs=[chatbot_ui, msg_box, cast_result, agent_stats, reasoning_display]
            )

            clear_chat_btn.click(
                lambda: ([], "", "", {}, []), 
                outputs=[chatbot_ui, msg_box, cast_result, agent_stats, reasoning_display]
            )
            
            # Enhanced examples vá»›i diverse use cases
            with gr.Accordion("ğŸ“ VÃ­ dá»¥ cÃ¢u há»i theo tá»«ng mode", open=False):
                gr.Markdown("**ğŸ² DÃ nh cho 'Gieo Quáº» vÃ  Luáº­n Giáº£i' (TÆ° váº¥n cÃ¡ nhÃ¢n):**")
                gr.Examples(
                    examples=[
                        "TÃ´i Ä‘ang cÃ¢n nháº¯c chuyá»ƒn viá»‡c, xin cho tÃ´i má»™t lá»i khuyÃªn.",
                        "Má»‘i quan há»‡ cá»§a tÃ´i vÃ  ngÆ°á»i áº¥y sáº½ Ä‘i vá» Ä‘Ã¢u?",
                        "CÃ´ng viá»‡c kinh doanh sáº¯p tá»›i cá»§a tÃ´i cÃ³ thuáº­n lá»£i khÃ´ng?",
                        "TÃ´i nÃªn lÃ m gÃ¬ Ä‘á»ƒ cáº£i thiá»‡n sá»©c khá»e cá»§a mÃ¬nh?",
                        "TÃ´i Ä‘ang muá»‘n Ä‘i du lá»‹ch vÃ o thÃ¡ng nÃ y, hÃ£y cho tÃ´i lá»i khuyÃªn."
                    ],
                    inputs=msg_box,
                    label=""
                )
                
                gr.Markdown("**ğŸ’¬ DÃ nh cho 'Há»i Nhanh' (Há»c há»i kiáº¿n thá»©c):**")
                gr.Examples(
                    examples=[
                        "Quáº» CÃ¡ch cÃ³ Ã½ nghÄ©a gÃ¬ trong Kinh Dá»‹ch?",
                        "Triáº¿t lÃ½ Ã¢m dÆ°Æ¡ng Ä‘Æ°á»£c hiá»ƒu nhÆ° tháº¿ nÃ o?",
                        "64 quáº» Kinh Dá»‹ch Ä‘Æ°á»£c chia thÃ nh máº¥y nhÃ³m?",
                        "HÃ o Ä‘á»™ng trong quáº» cÃ³ tÃ¡c dá»¥ng gÃ¬?",
                        "Thá»© tá»± 8 quáº» cÆ¡ báº£n lÃ  gÃ¬?"
                    ],
                    inputs=msg_box,
                    label=""
                )
        
        return interface

def main():
    app = MultiAgentKinhDichApp()
    interface = app.create_interface()
    
    print("ğŸ¤– Multi-Agent Kinh Dá»‹ch Chatbot - HYBRID OPTIMIZED VERSION")
    print("ğŸš€ Agents: Dispatcher â†’ Linguistics â†’ Retrieval â†’ Reasoning")
    print("ğŸ¯ Features: Hexagram Context + Specialized Prompts + Enhanced UX")
    print("ğŸ”— Dual Modes:")
    print("   ğŸ² Gieo Quáº» vÃ  Luáº­n Giáº£i: Divination + Personal Guidance")  
    print("   ğŸ’¬ Há»i Nhanh: Pure Q&A + Knowledge Base")
    print("ğŸŒ Access: http://localhost:7860")
    
    interface.launch(
        server_name="127.0.0.1",
        server_port=7860,
        inbrowser=True
    )

if __name__ == "__main__":
    main()