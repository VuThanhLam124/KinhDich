{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf9d628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "cache_dir = Path(\n",
    "    input(\"Thư mục cache (Enter=./hugging_face): \").strip() or \"./hugging_face\"\n",
    ").expanduser().resolve()\n",
    "cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for var in [\n",
    "    \"TRANSFORMERS_CACHE\",\n",
    "    \"HF_HOME\",\n",
    "    \"HUGGINGFACE_HUB_CACHE\",\n",
    "    \"SENTENCE_TRANSFORMERS_HOME\",\n",
    "]:\n",
    "    os.environ[var] = str(cache_dir)\n",
    "\n",
    "print(\"Cache tại:\", cache_dir)\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "print(\"Embedding model ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27a1f30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, numpy as np\n",
    "from pymongo import MongoClient\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "client = MongoClient(\"mongodb+srv://thanhlamdev:lamvthe180779@cluster0.jvlxnix.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\")\n",
    "collection = client[\"kinhdich_kb\"][\"chunks\"]\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\", max_features=5000)\n",
    "\n",
    "# --- Regex entity extractor ---\n",
    "def parse_query(q: str):\n",
    "    q_low = q.lower()\n",
    "    hex_match  = re.search(r\"quẻ\\s+([a-zà-ỹ_]+)\", q_low, re.I)\n",
    "    hao_match  = re.search(r\"hào\\s+(sáu|chín)\\s+(đầu|hai|ba|bốn|năm|trên)\", q_low, re.I)\n",
    "    note_match = re.search(r\"\\[(\\d+)\\]\", q)\n",
    "\n",
    "    return {\n",
    "        \"hexagram\": hex_match.group(1).upper() if hex_match else None,\n",
    "        \"hao\": \" \".join(hao_match.groups()) if hao_match else None,\n",
    "        \"note_id\": note_match.group(1) if note_match else None,\n",
    "    }\n",
    "\n",
    "# --- Candidate retrieval ---\n",
    "def get_candidates(entities, N=200):\n",
    "    filt = []\n",
    "    if entities[\"hexagram\"]:\n",
    "        filt.append({\"hexagram\": entities[\"hexagram\"]})\n",
    "    if entities[\"note_id\"]:\n",
    "        filt.append({f\"note_links.{entities['note_id']}\": {\"$exists\": True}})\n",
    "    mongo_q = {\"$and\": filt} if filt else {}\n",
    "    proj = {\"_id\":1, \"text\":1, \"embedding\":1, \"hexagram\":1, \"source_page_range\":1}\n",
    "    return list(collection.find(mongo_q, proj).limit(N))\n",
    "\n",
    "# --- Hybrid rank ---\n",
    "def hybrid_rank(query, docs, entities, top_k=5, a=0.4, b=0.5, g=0.1):\n",
    "    corpus = [d[\"text\"] for d in docs]\n",
    "    tfidf  = vectorizer.fit_transform(corpus + [query])\n",
    "    kw_sim = (tfidf[-1] @ tfidf[:-1].T).toarray()[0]\n",
    "\n",
    "    q_vec  = embedding_model.embed_query(query)\n",
    "    emb_mat= np.array([d[\"embedding\"] for d in docs])\n",
    "    emb_sim= cosine_similarity([q_vec], emb_mat)[0]\n",
    "\n",
    "    ent_bonus = np.array([\n",
    "        1.0 if entities[\"hexagram\"] and d.get(\"hexagram\")==entities[\"hexagram\"] else 0.0\n",
    "        for d in docs\n",
    "    ])\n",
    "\n",
    "    final = a*kw_sim + b*emb_sim + g*ent_bonus\n",
    "    top = np.argsort(final)[::-1][:top_k]\n",
    "    return [docs[i] for i in top]\n",
    "\n",
    "# --- Smart search (public API) ---\n",
    "def smart_search(query:str, top_k=5):\n",
    "    entities = parse_query(query)\n",
    "    if entities[\"note_id\"]:\n",
    "        d = collection.find_one({f\"note_links.{entities['note_id']}\": {\"$exists\":True}})\n",
    "        return [d] if d else []\n",
    "    docs = get_candidates(entities)\n",
    "    if not docs:\n",
    "        docs = list(collection.find({}, {\"_id\":1,\"text\":1,\"embedding\":1,\"hexagram\":1,\"source_page_range\":1}))\n",
    "    return hybrid_rank(query, docs, entities, top_k=top_k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "370f8255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kết quả cho: “quẻ khôn là gì”\n",
      "\n",
      "QUE_KIEN_026 | Quẻ: QUE_KIEN | Trang: [80, 128]\n",
      "  Thuyết của Tiên nho cho là biến cả thì bỏ quẻ gốc xem quẻ biến nhưng Kiền, Khôn là nghĩa lớn của trời đất, quẻ Kiền biến sang quẻ Khôn, chưa thể dùng toàn lời của quẻ Khôn quẻ Khôn tuy biến sang quẻ Kiền, chưa thể dùng toàn lời của quẻ Kiền, cho nên dựng riêng ra hào Dùng Chín, Dùng Sáu để làm phép chiêm khi hay quẻ ấy biến cả Thuyết đó cũng phải Lấy lý mà xét, thì phàm các quẻ, tuy là biến cả cũn…\n",
      "\n",
      "QUE_KHON_008 | Quẻ: QUE_KHON | Trang: [129, 154]\n",
      "  “Đi đất không bờ” chỉ về đức mạnh - Kiền mạnh, Khôn thuận, Khôn cũng mạnh ư? Đáp rằng: Không mạnh thì sao sánh được với Kiền? Chưa có bao giờ Kiền đi mà Khôn đỗ Nó động thì cứng, nhưng với đức mềm vẫn không hại gì Mềm thuận mà lợi về nết trinh là đức của Khôn, điều mà quân tử vẫn làm Đó là đạo của quân tử với đức Khôn Bản nghĩa của Chu Hy - Đây nói về lợi trinh Ngựa là tượng của Kiền mà lại cho là…\n",
      "\n",
      "QUE_KIEN_025 | Quẻ: QUE_KIEN | Trang: [80, 128]\n",
      "  Phàm việc xem bói, dùng số Chín, dùng số Sáu là dùng hào biến mà xem Gặp quẻ Kiền mà sáu hào đều biến, là Âm, gặp quẻ Khôn mà sáu hào đều biến, là Dương Hồ Quảng nói rằng: Lời hào tuy để phát minh về lý của quẻ thật ra chỉ dùng về bói toán, cho nên dùng số Chín và số Sáu mà đặt tên hào, là cốt lấy ở chỗ dùng của nó Lời hào động thì dùng, không động thì không dùng, lời quẻ bất luận động hay không đ…\n",
      "\n",
      "\n",
      "Kết quả cho: “QUE KIEN”\n",
      "\n",
      "QUE_DINH_019 | Quẻ: QUE_DINH | Trang: [766, 777]\n",
      "  GIẢI NGHĨA Truyện của Trình Di - Hào Năm ở trên quẻ Đỉnh, là Tượng tai vạc Cái vạc nhắc lên đặt xuống, cốt ở cái tai, nên nó là chủ quẻ Đỉnh, hào Năm có đức giữa, cho nên nói là tai vàng Quai là vật để vào cái tai hào Hai ứng với hào Năm, đến theo cái tai, tức là cái quai Hào Hai có đức cứng giữa, thể Dương cứng giữa sắc vàng, cho nên nói là quai màu vàng Hào Năm văn vẻ sáng sủa, được chỗ giữa mà …\n",
      "\n",
      "QUE_DOAI_016 | Quẻ: QUE_DOAI | Trang: [864, 873]\n",
      "  GIẢI NGHĨA Truyện của Trình Di - Đẹp lòng đã cùng cực, lại dẫn cho dài ra, tuy là bung “đẹp lòng” đó không thôi mà sự lý đã quá, thật không có gì đẹp lòng Việc đến khi thinh thì có sáng sủa, mà miễn cưỡng dẫn cho dài ra, thì vô ý vị tệ lắm, há có sáng sủa? “chưa” là tiếng “chẳng ắt hẳn”, trong lời Tượng dùng nhiều “chẳng ắt hẳn có sáng sủa” nghĩa là không thể sáng sủa…\n",
      "\n",
      "QUE_DAI_TRANG_018 | Quẻ: QUE_DAI_TRANG | Trang: [546, 556]\n",
      "  GIẢI NGHĨA Truyện của Trình Di - Ở không phải chỗ, cho nên không thể tiến lui, ấy là tự xử không được tinh tường cẩn thận Khó thì tốt, nghĩa là chất mềm gặp sự khó nhọc, lại ở vào cuối cuộc mạnh, tự nó nên phải biến đổi, biến đổi thì hợp với phận, tội lỗi không thể lâu dài mới được tốt lành Chú thích:…\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def show(docs, q):\n",
    "    print(f\"\\nKết quả cho: “{q}”\\n\")\n",
    "    for d in docs:\n",
    "        print(f\"{d['_id']} | Quẻ: {d.get('hexagram','?')} | Trang: {d.get('source_page_range')}\")\n",
    "        print(\"  \"+d[\"text\"][:400].replace(\"\\n\",\" \")+\"…\\n\")\n",
    "\n",
    "while True:\n",
    "    q = input(\"\\nHỏi Kinh Dịch (Enter thoát): \").strip()\n",
    "    if not q: break\n",
    "    docs = smart_search(q, top_k=3)\n",
    "    show(docs, q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6f249fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\anaconda3\\envs\\kinhdich\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in D:\\KinhDich\\Source\\hf_cache\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded embedding model.\n"
     ]
    }
   ],
   "source": [
    "import os, re, json, unicodedata, difflib\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import numpy as np\n",
    "from pymongo import MongoClient\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from underthesea import word_tokenize\n",
    "\n",
    "# ───────────────────── 1. Khởi tạo cache & embedding ────────────────────────────\n",
    "CACHE_DIR = Path(\"./hf_cache\").resolve()\n",
    "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "for v in [\"TRANSFORMERS_CACHE\", \"HF_HOME\",\n",
    "          \"HUGGINGFACE_HUB_CACHE\", \"SENTENCE_TRANSFORMERS_HOME\"]:\n",
    "    os.environ[v] = str(CACHE_DIR)\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "print(\"Loaded embedding model.\")\n",
    "\n",
    "# stop-word VN (file nhỏ, có sẵn)\n",
    "STOP = {\"và\", \"là\", \"của\", \"cho\", \"trong\", \"một\", \"các\", \"đã\", \"với\", \"không\"}\n",
    "def tokenize_vi(text: str) -> str:\n",
    "    toks = word_tokenize(text, format=\"text\").split()\n",
    "    return \" \".join(t for t in toks if t.lower() not in STOP)\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=tokenize_vi,\n",
    "                             lowercase=False,\n",
    "                             max_features=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2a3051ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MongoDB.\n",
      "Mapped 61 hexagrams.\n"
     ]
    }
   ],
   "source": [
    "# ───────────────────── 2. Kết nối MongoDB ───────────────────────────────────────\n",
    "MONGO_URI = \"mongodb+srv://thanhlamdev:lamvthe180779@cluster0.jvlxnix.mongodb.net/?retryWrites=true&w=majority\"\n",
    "client     = MongoClient(MONGO_URI)\n",
    "collection = client[\"kinhdich_kb\"][\"chunks\"]\n",
    "print(\"Connected to MongoDB.\")\n",
    "\n",
    "# ───────────────────── 3. Sinh bảng ánh xạ quẻ tự động ─────────────────────────\n",
    "def strip_accents(txt: str) -> str:\n",
    "    return \"\".join(c for c in unicodedata.normalize(\"NFD\", txt)\n",
    "                   if unicodedata.category(c) != \"Mn\")\n",
    "\n",
    "def _norm(code: str) -> str:\n",
    "    \"\"\"QUE_DONG_NHAN → 'dongnhan'  |  QUE_TON_2 → 'ton2' \"\"\"\n",
    "    return strip_accents(code.split('_', 1)[-1]).lower().replace('_', '')\n",
    "\n",
    "HEX_NORMALIZE: Dict[str, str] = {\n",
    "    _norm(code): code for code in collection.distinct(\"hexagram\")\n",
    "}\n",
    "print(f\"Mapped {len(HEX_NORMALIZE)} hexagrams.\")\n",
    "\n",
    "# ───────────────────── 4. Hàm nhận diện quẻ ────────────────────────────────────\n",
    "def detect_hexagram(query: str) -> str | None:\n",
    "    plain = strip_accents(query.lower())\n",
    "    # lấy từ cuối câu hoặc sau “quẻ ”\n",
    "    m = re.search(r\"(?:que\\s+)?([a-z0-9_ ]{2,})$\", plain)\n",
    "    if not m:\n",
    "        return None\n",
    "    key = m.group(1).replace(' ', '')\n",
    "    if key in HEX_NORMALIZE:\n",
    "        return HEX_NORMALIZE[key]\n",
    "    close = difflib.get_close_matches(key, HEX_NORMALIZE.keys(), n=1, cutoff=0.82)\n",
    "    return HEX_NORMALIZE[close[0]] if close else None\n",
    "\n",
    "# ───────────────────── 5. Smart-search pipeline ────────────────────────────────\n",
    "def parse_entities(q: str) -> Dict[str, str | None]:\n",
    "    note = re.search(r\"\\[(\\d+)\\]\", q)\n",
    "    return {\"hexagram\": detect_hexagram(q),\n",
    "            \"note_id\":  note.group(1) if note else None}\n",
    "\n",
    "def get_candidates(entities, N=300) -> List[Dict[str,Any]]:\n",
    "    flt = []\n",
    "    if entities[\"hexagram\"]:\n",
    "        flt.append({\"hexagram\": entities[\"hexagram\"]})\n",
    "    if entities[\"note_id\"]:\n",
    "        flt.append({f\"note_links.{entities['note_id']}\": {\"$exists\": True}})\n",
    "    q = {\"$and\": flt} if flt else {}\n",
    "    proj = {\"_id\":1,\"text\":1,\"embedding\":1,\"hexagram\":1,\"source_page_range\":1}\n",
    "    return list(collection.find(q, proj).limit(N))\n",
    "\n",
    "def hybrid_rank(query: str, docs: List[Dict[str,Any]],\n",
    "                hex_code: str | None,\n",
    "                top_k=5, α=0.25, β=0.25, γ=0.5):\n",
    "    if not docs:\n",
    "        return []\n",
    "    tfidf = vectorizer.fit_transform([d[\"text\"] for d in docs] + [query])\n",
    "    kw_sim = (tfidf[-1] @ tfidf[:-1].T).toarray()[0]\n",
    "\n",
    "    q_vec   = embedding_model.embed_query(query)\n",
    "    emb_mat = np.array([d[\"embedding\"] for d in docs])\n",
    "    emb_sim = cosine_similarity([q_vec], emb_mat)[0]\n",
    "\n",
    "    bonus = np.array([1.0 if hex_code and d[\"hexagram\"] == hex_code else 0.0\n",
    "                      for d in docs])\n",
    "\n",
    "    score = α*kw_sim + β*emb_sim + γ*bonus\n",
    "    rank  = np.argsort(score)[::-1][:top_k]\n",
    "    return [docs[i] for i in rank]\n",
    "\n",
    "def smart_search(query: str, top_k=5) -> List[Dict[str,Any]]:\n",
    "    ent = parse_entities(query)\n",
    "\n",
    "    # ghi chú [n]\n",
    "    if ent[\"note_id\"]:\n",
    "        d = collection.find_one({f\"note_links.{ent['note_id']}\": {\"$exists\": True}})\n",
    "        return [d] if d else []\n",
    "\n",
    "    # Query 1 từ → ưu tiên hexagram regex\n",
    "    if len(query.split()) == 1:\n",
    "        code = ent[\"hexagram\"]\n",
    "        if code:\n",
    "            return list(collection.find(\n",
    "                {\"hexagram\": code},\n",
    "                {\"_id\":1,\"text\":1,\"hexagram\":1,\"source_page_range\":1}\n",
    "            ).limit(top_k))\n",
    "\n",
    "    cand = get_candidates(ent)\n",
    "    if not cand:\n",
    "        cand = get_candidates({}, N=1000)\n",
    "    return hybrid_rank(query, cand, ent[\"hexagram\"], top_k=top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e63ec21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\anaconda3\\envs\\kinhdich\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kết quả cho: “quẻ càn”\n",
      "\n",
      "QUE_CAN_001 | QUE_CAN | Trang [790, 801]\n",
      "  QUẺ CẤN ☶ Cấn trên ☶ Cấn dưới GIẢI NGHĨA Truyện của Trình Di - Quẻ Cấn, Tự quái nói rằng: Chấn là động, các vật  ngăn, động với tĩnh phải nhân nhau, động thì có tĩnh, tĩnh thì có động, các vật không lẽ động luôn, vì vậy quẻ Cấn mới nối quẻ Chấn Cấn là đậu, không nói đậu mà nói cấn, là vì Cấn là Tượng núi, có ý yên nặng rắn đặc, nghĩa chữ “đậu” không thể hết được Kiền Khôn giao nhau, ba lần mà thàn…\n",
      "\n",
      "QUE_CAN_002 | QUE_CAN | Trang [790, 801]\n",
      "  Dịch âm - Cấn kỳ bối, bất hoạch kỳ thân, thành kỳ đình, bất kiến kỳ nhân, vô cữu Dịch nghĩa - Đậu thửa lưng, chẳng được thửa mình, đi thửa sân, chẳng thấy thửa người, không lỗi GIẢI NGHĨA  về sự ham muốn Sự ham muốn có kéo ở đằng trước, mà cần nó đậu thì không thể được, cho nên đạo đậu, nên đậu cái lưng Những cái trông thấy đều ở đằng trước, mà lưng thì trái ngược lại, ấy là nó không trông thấy Đậ…\n",
      "\n",
      "QUE_CAN_007 | QUE_CAN | Trang [790, 801]\n",
      "  Âm Dương chọi ứng với nhau mà không cùng nhau Không cùng nhau thì trong chẳng thấy mình, ngoài chẳng thấy mình, và không có lỗi Họ Triều nói rằng: “Câu ⾉ 其 ⽌ cấn kỳ chỉ”, chữ ⽌ (chỉ) nên theo lời  LỜI KINH 象 ⽈: 兼 ⼭ ⾉, 君 ⼦ 以 思 不 出 其 位 Dịch âm - Tượng viết: Kiêm sơn Cấn, quân tử dĩ tư bất xuất kỳ vị Dịch nghĩa - Lời Tượng nói rằng: Gồm núi là quẻ Cấn Đấng quân tử coi đó mà nghĩ chẳng việc thửa ngôi …\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\anaconda3\\envs\\kinhdich\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kết quả cho: “quẻ khôn”\n",
      "\n",
      "QUE_KHON_001 | QUE_KHON | Trang [129, 154]\n",
      "  QUẺ KHÔN Khôn trên Khôn dưới LỜI KINH 坤元亨,利牝⾺之貞,君⼦有攸往,先迷,後得,主利,西南得朋,東北喪朋 安 貞,吉 Dịch âm - Khôn nguyên hanh, lợi tẫn mã chi trinh Quân tử hữu du vãng Tiên mê, hậu đắc, chủ lợi Tây Nam đắc bằng, Đông Bắc táng bằng, an trinh, cát Dịch nghĩa - Quẻ khôn: Đầu cả, hanh thông, Lợi về nết trinh của ngựa cái Quân tử có sự đi Trước mê, sau được Chủ về lợi Phía Tây Nam được bạn, phía Đông Bắc mất bạn Yên phận …\n",
      "\n",
      "QUE_KHON_013 | QUE_KHON | Trang [129, 154]\n",
      "  - Lời Tượng nói rằng: Thế đất là quẻ Khôn, đấng quân tử coi đó mà dùng đức dày chở các vật GIẢI NGHĨA Truyệu của Trình Di - Đạo Khôn cũng lớn như Kiền, phi thánh nhân ai thể được nó? Đất dày mà thế của nó xuôi nghiêng, cho nên lấy cái hình tượng xuôi thuận và dày đó mà nói “thế đất là quẻ Khôn” Đấng quân tử coi cái hình tượng Khôn dày mà đem cái đức thâm hậu chứa chở các vật Bản nghĩa của Chu Hy -…\n",
      "\n",
      "QUE_KHON_007 | QUE_KHON | Trang [129, 154]\n",
      "  LỜI KINH 牦⾺地類,⾏地無疆,柔順利負,君⼦攸⾏ Dịch âm – Tẫn mã địa loại, hành địa vô cương, nhu thuận lợi trinh quân tử du hành Dịch nghĩa - Ngựa cái là loài của đất,đi đất không bờ, mềm, thuận, lợi về nết trinh, đấng quân tử thửa làm GIẢI NGHĨA Truyện của Trình Di - Dùng bốn chữ “hàm”, “hoằng”,“quang” “đại” để hình dung đạo Khôn, cũng như những đức cương, kiện, trung, chính, thuần, túy của Kiền vậy Hàm là bao dun…\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\anaconda3\\envs\\kinhdich\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kết quả cho: “quẻ cách”\n",
      "\n",
      "QUE_CACH_015 | QUE_CACH | Trang [753, 765]\n",
      "  Nhưng đạo làm tôi, không nên làm kẻ đi trước trong cuộc thay đổi, ắt đợi trên dưới tin mình, cho nên hết ngày mới đổi Như tài đức của hào Hai này, và cái chỗ nó ở, cái thì nó gặp, đủ để đổi thay điều tệ của thiên hạ, làm mới cuộc trị cho thiên hạ, nên tiến lên mà giúp vua, để thực hành cái đạo của mình, thì tốt mà không có lỗi Nếu không tiến lên thì mất cơ hội có thể làm việc, tức là có lỗi Bản ng…\n",
      "\n",
      "QUE_CACH_001 | QUE_CACH | Trang [753, 765]\n",
      "  QUẺ CÁCH ☱ Đoái trên ☲ Ly dưới GIẢI NGHĨA Truyện của Trình Di - Quẻ Cách Tự quái nói rằng: Đào giếng không thể  hỏng, đổi đi thì trong sạch, không thể không đổi, cho nên ở sau quẻ Tỉnh, tiếp đến quẻ Cách Nó là quẻ Đoái trên Ly dưới, tức là trong chằm có lửa Cách là biến đổi, nước lửa là giống làm tắt lẫn nhau, nước diệt lửa, lửa làm cạn nước, ấy là biến đổi cho nhau Tính lửa bốc lên, tính nước chả…\n",
      "\n",
      "QUE_CACH_004 | QUE_CACH | Trang [753, 765]\n",
      "  Giải vậy cũng hay Hào Đầu là đáy lò, hào Hai là mặt lò, hào Ba, hào Tư, hào Năm là chỗ lưng lò, hào Trên là miệng lò Trong quẻ, muốn xem đến nơi đến chốn, cần phải xem gồm cả Tượng, có điều Tượng đã thất truyền mất rồi Trịnh Đông Hương là người chuyên lấy về Tượng, như bảo quẻ Đỉnh là cái vạc, quẻ Cách là cái lò, quẻ Tiểu quá là con chim bay, cũng đủ nghĩa lý, ngoài ra còn nhiều chỗ hay, nhưng cũn…\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ───────────────────── 6. CLI demo ──────────────────────────────────────────────\n",
    "def show(docs, q):\n",
    "    print(f\"\\nKết quả cho: “{q}”\\n\")\n",
    "    if not docs:\n",
    "        print(\"Không tìm thấy.\")\n",
    "        return\n",
    "    for d in docs:\n",
    "        snip = d[\"text\"][:400].replace(\"\\n\",\" \")\n",
    "        print(f\"{d['_id']} | {d['hexagram']} | Trang {d.get('source_page_range')}\")\n",
    "        print(\"  \"+snip+\"…\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    while True:\n",
    "        q = input(\"\\nHỏi Kinh Dịch (Enter để thoát): \").strip()\n",
    "        if not q:\n",
    "            break\n",
    "        show(smart_search(q, top_k=3), q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a98687",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kinhdich",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
